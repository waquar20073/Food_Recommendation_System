{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have used these 4 libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math, joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Intersection(lst1, lst2):\n",
    "    return list(set(lst1).intersection(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_UB(userId, itemId, train_pt_df, sm_df, K):\n",
    "    # Check if a completly new movie comes in my testing dataset.\n",
    "    try:\n",
    "        users_similarities = sm_df[userId]   # cosine similarities of user 'userId' with all other users.\n",
    "        users_ratings = train_pt_df[itemId]  # ratings of all users for item 'itemId'\n",
    "    except:\n",
    "        return -1   # That movie doesn't exit in my training dataset. Ignore this case.\n",
    "    \n",
    "    # Consider only highest K item similarities. (Here, similarity of the same item will also not considered).\n",
    "    d = dict(users_similarities) # {itemId : item_similarity}\n",
    "    d_sorted = {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "    drop_rest_users = list(d_sorted.keys())\n",
    "    drop_rest_users = drop_rest_users[K:]\n",
    "    users_ratings = users_ratings.drop(drop_rest_users)\n",
    "    users_similarities = users_similarities.drop(drop_rest_users)\n",
    "    \n",
    "    # Not consider users who haven't rated the movie 'itemId'\n",
    "    drop_indices = users_ratings[users_ratings == 0].index\n",
    "    users_ratings = users_ratings.drop(drop_indices)\n",
    "    users_similarities = users_similarities.drop(drop_indices)\n",
    "    \n",
    "    global coverage\n",
    "    # If I encountered with coverage problem i.e, no similar users exist after threshold. Then take aveage rating of the movie.\n",
    "    if len(users_similarities) == 0 or len(users_ratings) == 0:\n",
    "        coverage = coverage + 1\n",
    "        return -1\n",
    "    else:\n",
    "        l = [x for x in list(train_pt_df.loc[userId]) if x != 0]\n",
    "        if len(l)==0:\n",
    "            ru = 2.5\n",
    "        else:\n",
    "            ru = sum(l)/len(l)\n",
    "        \n",
    "        num = 0\n",
    "        for user, sim in dict(users_similarities).items():\n",
    "            rji = train_pt_df[itemId][user]\n",
    "            l = [x for x in list(train_pt_df.loc[user]) if x != 0]\n",
    "            rj = sum(l)/len(l) \n",
    "            num += sim * (rji - rj)\n",
    "        \n",
    "        den = sum([abs(sim) for sim in users_similarities])\n",
    "        \n",
    "        if math.isnan(ru + (num/den)) ==  False:\n",
    "            return (ru + (num/den))\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the training & testing dataframes and return the MAE.\n",
    "def UB_MAE(train_df, test_df, K):\n",
    "    # pivot the training dataframe.\n",
    "    train_pt_df = pd.pivot_table(train_df, values='Rating', index='userId', columns='itemId')\n",
    "    # Replace the NA values with 0   (Note: I observed -> No user in the whole dataset have rated 0 to any movie)\n",
    "    train_pt_df = train_pt_df.fillna(0)\n",
    "    # Calculate the cosine similarities of user-user.\n",
    "    sm_df = pd.DataFrame(np.corrcoef(train_pt_df), index=train_pt_df.index, columns=train_pt_df.index)\n",
    "    # Not consider the similarity of same user while predicting the rating. eg: similarity of user 1 with user 1.\n",
    "    np.fill_diagonal(sm_df.values, 0)\n",
    "    \n",
    "    d = {}\n",
    "    for user in train_df['userId'].unique().tolist():\n",
    "        d[user] = train_df[train_df['userId']==user]['itemId'].tolist()\n",
    "        \n",
    "    UserCount = {user:len(d[user]) for user in list(d.keys())}\n",
    "    \n",
    "    threshold = {}\n",
    "    for user in list(d.keys()):\n",
    "        other_users = list(set(list(d.keys())).difference([user]))\n",
    "        l = []\n",
    "        for other_u in other_users:\n",
    "            l.append(len(Intersection(d[user], d[other_u])))\n",
    "        threshold[user] = sum(l)/len(l)\n",
    "\n",
    "    for i in tqdm(sm_df.index):\n",
    "        for j in sm_df.columns:\n",
    "            y = len(Intersection(d[i], d[j]))\n",
    "            if y >= threshold[i] and y >= threshold[j]:\n",
    "                num = 2 * len(Intersection(d[i], d[j]))\n",
    "                den = len(d[i]) + len(d[j])\n",
    "                sm_df[i][j] = sm_df[i][j] * (num/den) \n",
    "            else:\n",
    "                pi = abs(y - UserCount[i])\n",
    "                pj = abs(y - UserCount[j])\n",
    "                sm_df[i][j] = ((pi/UserCount[i]) * sm_df[i][j]) + ((pj/UserCount[j]) * sm_df[i][j])\n",
    "    \n",
    "    \n",
    "    # Actual Ratings of testing dataframe.\n",
    "    actual_ratings  = list(test_df['Rating'])\n",
    "    # Start predicting the ratings of testing dataframe.\n",
    "    predicted_ratings = []\n",
    "    for userId, itemId in tqdm(zip(test_df['userId'], test_df['itemId'])):\n",
    "        predicted_ratings.append(predict_rating_UB(userId, itemId, train_pt_df, sm_df, K))\n",
    "    \n",
    "    # Ignore the case when predicted rating is -1. (Because no such users are available to predict the rating. #Coverage_Problem)\n",
    "    new_actual_ratings = []\n",
    "    new_predicted_ratings = []\n",
    "    for i in range(0, len(predicted_ratings)):\n",
    "        if predicted_ratings[i] <= 0:\n",
    "            continue\n",
    "        new_actual_ratings.append(actual_ratings[i])\n",
    "        new_predicted_ratings.append(predicted_ratings[i])\n",
    "    \n",
    "    # return the MAE between Actual Ratings & Predicted Ratings.\n",
    "    return mean_absolute_error(new_actual_ratings, new_predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1709/1709 [04:01<00:00,  7.09it/s]\n",
      "1016it [00:14, 69.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.49947657921027194 , Coverage = 91.43700787401575%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = joblib.load('./Dataset/finefoods.pkl')\n",
    "df = df.rename(columns={'rating': 'Rating'})\n",
    "\n",
    "d = (dict(enumerate(df['userId'].unique())))\n",
    "new_d = {}\n",
    "new_d = {value:key for key, value in d.items()}\n",
    "df['userId'] = df['userId'].map(new_d)\n",
    "\n",
    "d = (dict(enumerate(df['itemId'].unique())))\n",
    "new_d = {}\n",
    "new_d = {value:key for key, value in d.items()}\n",
    "df['itemId'] = df['itemId'].map(new_d)\n",
    "\n",
    "train, test = train_test_split(df[(df['userId']<2000) & (df['itemId']<10000)], test_size=0.2)\n",
    "\n",
    "coverage = 0\n",
    "mae_value = UB_MAE(train, test, 800)  # Returning MAE for each fold.\n",
    "print(\"MAE =\", mae_value, \", Coverage = \" + str(100-((coverage*100)/test.shape[0])) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
